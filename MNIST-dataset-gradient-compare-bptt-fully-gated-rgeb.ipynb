{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede197e5",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89b4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c606816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee1c2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05838d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bptt_tgeb_mnist_architecture import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b22af",
   "metadata": {},
   "source": [
    "#### Test for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ba2ce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU, training on CPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('No GPU, training on CPU')\n",
    "    dev = torch.device('cpu')\n",
    "else:\n",
    "    print('GPU found, training on GPU')\n",
    "    dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2b541",
   "metadata": {},
   "source": [
    "#### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d548a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure batch_size = 1 for now!!\n",
    "\n",
    "def load_mnist(batch_size=1, shuffle_train=True):\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_set = torchvision.datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "    test_set = torchvision.datasets.MNIST(\"../data\", train=False, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=shuffle_train)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a3feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_loader, mnist_test_loader = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d676eee",
   "metadata": {},
   "source": [
    "#### Architectural initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cca50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4512e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "hidden_dim = 100\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22c9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gating vector\n",
    "tvec_hh = torch.zeros(n_classes,hidden_dim)\n",
    "for ii in range(n_classes):\n",
    "    t_half = torch.randint(0, 2, (1, hidden_dim//2)).float()*2 - 1\n",
    "    tvec_hh[ii,::2] = t_half\n",
    "    tvec_hh[ii,1::2] = -t_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7669410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_ih = tvec_hh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f6be7",
   "metadata": {},
   "source": [
    "#### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6aca40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = RNNModule(input_dim, hidden_dim, output_dim, tvec_ih, tvec_hh)\n",
    "rnn = RNN(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590043bd",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e780b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(ys, ts):\n",
    "    return 0.5 * torch.sum((ys - ts)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0096a30f",
   "metadata": {},
   "source": [
    "#### Training-esque loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acb84ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_choice = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592d2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loader_choice == 'test':\n",
    "    loader = mnist_test_loader\n",
    "    len_dataset = 10000\n",
    "elif loader_choice == 'train':\n",
    "    loader = mnist_train_loader\n",
    "    len_dataset = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67e4961b",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 58.4 GiB for an array with shape (10000, 10, 100, 784) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46064\\1718554713.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mWoh_bp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mWih_geb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mWhh_geb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mWoh_geb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 58.4 GiB for an array with shape (10000, 10, 100, 784) and data type float64"
     ]
    }
   ],
   "source": [
    "Wih_bp = np.zeros((len_dataset,n_classes,hidden_dim,input_dim),dtype='float32')\n",
    "Whh_bp = np.zeros((len_dataset,n_classes,hidden_dim,hidden_dim),dtype='float32')\n",
    "Woh_bp = np.zeros((len_dataset,n_classes,output_dim,hidden_dim),dtype='float32')\n",
    "\n",
    "Wih_geb = np.zeros((len_dataset,n_classes,hidden_dim,input_dim),dtype='float32')\n",
    "Whh_geb = np.zeros((len_dataset,n_classes,hidden_dim,hidden_dim),dtype='float32')\n",
    "Woh_geb = np.zeros((len_dataset,n_classes,output_dim,hidden_dim),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faf8305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10760\\4143103258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mWih_bp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWih_grad_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mWhh_bp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWhh_grad_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mWoh_bp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWoh_grad_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "for ii, (image,label) in tqdm(enumerate(loader)):\n",
    "    \n",
    "    ## Change to appropriate shapes!!\n",
    "    image = torch.squeeze(image).view(1,-1)\n",
    "    image = image.repeat(n_classes,1)\n",
    "    label = F.one_hot(label,n_classes).view(-1,1)\n",
    "\n",
    "    xs = image\n",
    "    hp = torch.zeros(cell.hid_dim)\n",
    "    ts = label\n",
    "    \n",
    "    ## Forward pass\n",
    "    ys, hs = rnn.forward(xs, hp)\n",
    "    loss = compute_loss(ys, ts)\n",
    "    \n",
    "    ## Compute gradients w/ Backprop (autograd)\n",
    "    loss.backward()\n",
    "    \n",
    "    ## Manual gradients\n",
    "    ## Valid only for MSE!!\n",
    "    ys_grad = ys - ts\n",
    "\n",
    "    with torch.no_grad():  # required so PyTorch won't raise error\n",
    "        rnn.cell.zero_grad()\n",
    "        rnn.backward(ys_grad, xs, hs)\n",
    "        \n",
    "    for kk in range(n_classes):\n",
    "        Wih_bp[ii,kk] = rnn.cell.Wih_grad_all[kk]\n",
    "        Whh_bp[ii,kk] = rnn.cell.Whh_grad_all[kk]\n",
    "        Woh_bp[ii,kk] = rnn.cell.Woh_grad_all[kk]\n",
    "        \n",
    "        Wih_geb[ii,kk] = rnn.cell.Wih_grad_geb_all[kk]\n",
    "        Whh_geb[ii,kk] = rnn.cell.Whh_grad_geb_all[kk]\n",
    "        Woh_geb[ii,kk] = rnn.cell.Woh_grad_geb_all[kk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4506ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709dc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33eb821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clip_mini_grads(grad_dict, nSteps=10):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31f8ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc46c16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d21e7380",
   "metadata": {},
   "source": [
    "#### PyTorch gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "053ad27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gradient of cross entropy w.r.t. yhat_k = (1/yhat_k)*y_k\n",
    "## gradient of mse w.r.t. y_hat = y_hat - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ab2b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Wih.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4054d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Whh.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a8bce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Woh.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f07a3",
   "metadata": {},
   "source": [
    "#### Manual gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64a3eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is obtained from our loss function\n",
    "# ys_grad = torch.matmul(label_batch,ys)\n",
    "ys_grad = ys - ts\n",
    "\n",
    "with torch.no_grad():  # required so PyTorch won't raise error\n",
    "    rnn.cell.zero_grad()\n",
    "    rnn.backward(ys_grad, xs, hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ced17a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed total differences for Whh:  tensor([[2.9098, 6.6073, 3.2535,  ..., 7.0618, 6.2041, 4.5104],\n",
      "        [2.8203, 4.2550, 0.2491,  ..., 0.2389, 0.2248, 7.5119],\n",
      "        [1.0735, 6.3153, 1.1986,  ..., 6.6821, 6.5828, 1.6456],\n",
      "        ...,\n",
      "        [0.6296, 4.9521, 0.2488,  ..., 0.8699, 0.4176, 4.5638],\n",
      "        [0.1245, 9.8743, 0.2491,  ..., 5.4157, 5.5624, 4.5645],\n",
      "        [6.6030, 0.6977, 3.0078,  ..., 1.7924, 0.7971, 6.9081]])\n"
     ]
    }
   ],
   "source": [
    "print('Summed total differences for Whh: ',torch.abs(rnn.cell.Whh_grad - rnn.cell.Whh_grad_geb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6856c9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summed total differences for Wih:  tensor([[3.8722, 3.8722, 3.8722,  ..., 3.8722, 3.8722, 3.8722],\n",
      "        [3.2990, 3.2990, 3.2990,  ..., 3.2990, 3.2990, 3.2990],\n",
      "        [3.7147, 3.7147, 3.7147,  ..., 3.7147, 3.7147, 3.7147],\n",
      "        ...,\n",
      "        [4.3902, 4.3902, 4.3902,  ..., 4.3902, 4.3902, 4.3902],\n",
      "        [4.3657, 4.3657, 4.3657,  ..., 4.3657, 4.3657, 4.3657],\n",
      "        [4.3580, 4.3580, 4.3580,  ..., 4.3580, 4.3580, 4.3580]])\n"
     ]
    }
   ],
   "source": [
    "print('Summed total differences for Wih: ',torch.abs(rnn.cell.Wih_grad - rnn.cell.Wih_grad_geb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ef6f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tt in range(n_classes):\n",
    "#     print(tt)\n",
    "    \n",
    "#     rnn.cell.Wih_grad_all[tt][rnn.cell.Wih_grad_all[tt]==torch.clamp(rnn.cell.Wih_grad_all[tt], -1e-6 , 1e-6)]=0\n",
    "#     rnn.cell.Wih_grad_all[tt][rnn.cell.Wih_grad_geb_all[tt]==torch.clamp(rnn.cell.Wih_grad_geb_all[tt], -1e-6 , 1e-6)]=0\n",
    "    \n",
    "#     rnn.cell.Whh_grad_all[tt][rnn.cell.Whh_grad_all[tt]==torch.clamp(rnn.cell.Whh_grad_all[tt], -1e-6 , 1e-6)]=0\n",
    "#     rnn.cell.Whh_grad_all[tt][rnn.cell.Whh_grad_geb_all[tt]==torch.clamp(rnn.cell.Whh_grad_geb_all[tt], -1e-6 , 1e-6)]=0\n",
    "    \n",
    "#     rnn.cell.Woh_grad_all[tt][rnn.cell.Woh_grad_all[tt]==torch.clamp(rnn.cell.Woh_grad_all[tt], -1e-6 , 1e-6)]=0\n",
    "#     rnn.cell.Woh_grad_all[tt][rnn.cell.Woh_grad_geb_all[tt]==torch.clamp(rnn.cell.Woh_grad_geb_all[tt], -1e-6 , 1e-6)]=0\n",
    "    \n",
    "#     print('Timestep signed differences for Wih:',torch.unique(torch.sign(rnn.cell.Wih_grad_all[tt]) - torch.sign(rnn.cell.Wih_grad_geb_all[tt])))\n",
    "#     print('Timestep signed differences for Whh:',torch.unique(torch.sign(rnn.cell.Whh_grad_all[tt]) - torch.sign(rnn.cell.Whh_grad_geb_all[tt])))\n",
    "#     print('Timestep signed differences for Woh:',torch.unique(torch.sign(rnn.cell.Woh_grad_all[tt]) - torch.sign(rnn.cell.Woh_grad_geb_all[tt])))\n",
    "#     print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b9561aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Frac. 0 signed differences for Wih: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "1\n",
      "Frac. 0 signed differences for Wih: 0.32\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 0.7316\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "2\n",
      "Frac. 0 signed differences for Wih: 0.66\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "3\n",
      "Frac. 0 signed differences for Wih: 0.62\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "4\n",
      "Frac. 0 signed differences for Wih: 0.56\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "5\n",
      "Frac. 0 signed differences for Wih: 0.52\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "6\n",
      "Frac. 0 signed differences for Wih: 0.52\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "7\n",
      "Frac. 0 signed differences for Wih: 0.52\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "8\n",
      "Frac. 0 signed differences for Wih: 0.52\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n",
      "9\n",
      "Frac. 0 signed differences for Wih: 0.52\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Whh: 1.0\n",
      "-----------------------\n",
      "Frac. 0 signed differences for Woh: 1.0\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "for tt in range(n_classes):\n",
    "    \n",
    "    print(tt)\n",
    "    \n",
    "    totWih = np.prod(rnn.cell.Wih_grad_all[tt].shape)\n",
    "    totWhh = np.prod(rnn.cell.Whh_grad_all[tt].shape)\n",
    "    totWoh = np.prod(rnn.cell.Woh_grad_all[tt].shape)\n",
    "    \n",
    "#     rnn.cell.Wih_grad_all[tt][rnn.cell.Wih_grad_all[tt]==torch.clamp(rnn.cell.Wih_grad_all[tt], -1e-6 , 1e-6)]=0\n",
    "#     rnn.cell.Wih_grad_all[tt][rnn.cell.Wih_grad_geb_all[tt]==torch.clamp(rnn.cell.Wih_grad_geb_all[tt], -1e-6 , 1e-6)]=0\n",
    "    \n",
    "#     rnn.cell.Whh_grad_all[tt][rnn.cell.Whh_grad_all[tt]==torch.clamp(rnn.cell.Whh_grad_all[tt], -1e-6 , 1e-6)]=0\n",
    "#     rnn.cell.Whh_grad_all[tt][rnn.cell.Whh_grad_geb_all[tt]==torch.clamp(rnn.cell.Whh_grad_geb_all[tt], -1e-6 , 1e-6)]=0\n",
    "    \n",
    "#     rnn.cell.Woh_grad_all[tt][rnn.cell.Woh_grad_all[tt]==torch.clamp(rnn.cell.Woh_grad_all[tt], -1e-6 , 1e-6)]=0\n",
    "#     rnn.cell.Woh_grad_all[tt][rnn.cell.Woh_grad_geb_all[tt]==torch.clamp(rnn.cell.Woh_grad_geb_all[tt], -1e-6 , 1e-6)]=0\n",
    "    \n",
    "    num0_Wih = len(np.where((torch.sign(rnn.cell.Wih_grad_all[tt]) - torch.sign(rnn.cell.Wih_grad_geb_all[tt]))==0)[0])\n",
    "    num1_Wih = len(np.where((torch.sign(rnn.cell.Wih_grad_all[tt]) - torch.sign(rnn.cell.Wih_grad_geb_all[tt]))==1)[0])\n",
    "    num2_Wih = len(np.where((torch.sign(rnn.cell.Wih_grad_all[tt]) - torch.sign(rnn.cell.Wih_grad_geb_all[tt]))==2)[0])\n",
    "    numm1_Wih = len(np.where((torch.sign(rnn.cell.Wih_grad_all[tt]) - torch.sign(rnn.cell.Wih_grad_geb_all[tt]))==-1)[0])\n",
    "    numm2_Wih = len(np.where((torch.sign(rnn.cell.Wih_grad_all[tt]) - torch.sign(rnn.cell.Wih_grad_geb_all[tt]))==-2)[0])\n",
    "    \n",
    "    num0_Whh = len(np.where((torch.sign(rnn.cell.Whh_grad_all[tt]) - torch.sign(rnn.cell.Whh_grad_geb_all[tt]))==0)[0])\n",
    "    num1_Whh = len(np.where((torch.sign(rnn.cell.Whh_grad_all[tt]) - torch.sign(rnn.cell.Whh_grad_geb_all[tt]))==1)[0])\n",
    "    num2_Whh = len(np.where((torch.sign(rnn.cell.Whh_grad_all[tt]) - torch.sign(rnn.cell.Whh_grad_geb_all[tt]))==2)[0])\n",
    "    numm1_Whh = len(np.where((torch.sign(rnn.cell.Whh_grad_all[tt]) - torch.sign(rnn.cell.Whh_grad_geb_all[tt]))==-1)[0])\n",
    "    numm2_Whh = len(np.where((torch.sign(rnn.cell.Whh_grad_all[tt]) - torch.sign(rnn.cell.Whh_grad_geb_all[tt]))==-2)[0])\n",
    "    \n",
    "    num0_Woh = len(np.where((torch.sign(rnn.cell.Woh_grad_all[tt]) - torch.sign(rnn.cell.Woh_grad_geb_all[tt]))==0)[0])\n",
    "    num1_Woh = len(np.where((torch.sign(rnn.cell.Woh_grad_all[tt]) - torch.sign(rnn.cell.Woh_grad_geb_all[tt]))==1)[0])\n",
    "    num2_Woh = len(np.where((torch.sign(rnn.cell.Woh_grad_all[tt]) - torch.sign(rnn.cell.Woh_grad_geb_all[tt]))==2)[0])\n",
    "    numm1_Woh = len(np.where((torch.sign(rnn.cell.Woh_grad_all[tt]) - torch.sign(rnn.cell.Woh_grad_geb_all[tt]))==-1)[0])\n",
    "    numm2_Woh = len(np.where((torch.sign(rnn.cell.Woh_grad_all[tt]) - torch.sign(rnn.cell.Woh_grad_geb_all[tt]))==-2)[0])\n",
    "    \n",
    "    print('Frac. 0 signed differences for Wih:',num0_Wih/totWih)\n",
    "#     print('Frac. 1 signed differences for Wih:',num1_Wih/totWih)\n",
    "#     print('Frac. 2 signed differences for Wih:',num2_Wih/totWih)\n",
    "#     print('Frac. -1 signed differences for Wih:',numm1_Wih/totWih)\n",
    "#     print('Frac. -2 signed differences for Wih:',numm2_Wih/totWih)\n",
    "    print('-----------------------')\n",
    "    print('Frac. 0 signed differences for Whh:',num0_Whh/totWhh)\n",
    "#     print('Frac. 1 signed differences for Whh:',num1_Whh/totWhh)\n",
    "#     print('Frac. 2 signed differences for Whh:',num2_Whh/totWhh)\n",
    "#     print('Frac. -1 signed differences for Whh:',numm1_Whh/totWhh)\n",
    "#     print('Frac. -2 signed differences for Whh:',numm2_Whh/totWhh)\n",
    "    print('-----------------------')\n",
    "    print('Frac. 0 signed differences for Woh:',num0_Woh/totWoh)\n",
    "#     print('Frac. 1 signed differences for Woh:',num1_Woh/totWoh)\n",
    "#     print('Frac. 2 signed differences for Woh:',num2_Woh/totWoh)\n",
    "#     print('Frac. -1 signed differences for Woh:',numm1_Woh/totWoh)\n",
    "#     print('Frac. -2 signed differences for Woh:',numm2_Woh/totWoh)\n",
    "    print('=======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee75f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

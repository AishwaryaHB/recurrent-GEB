{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca17571",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a520a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c860c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395eacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vnn\n",
    "import vec_models\n",
    "import nonvec_models\n",
    "import init_methods\n",
    "import dfa_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550eaa5b",
   "metadata": {},
   "source": [
    "#### Test for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc5d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU, training on CPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('No GPU, training on CPU')\n",
    "    dev = torch.device('cpu')\n",
    "else:\n",
    "    print('GPU found, training on GPU')\n",
    "    dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c57fb8",
   "metadata": {},
   "source": [
    "#### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec5d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(batch_size=128, shuffle_train=True):\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_set = torchvision.datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "    test_set = torchvision.datasets.MNIST(\"../data\", train=False, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=shuffle_train)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02851034",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_loader, mnist_test_loader = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b07a7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in mnist_train_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213729b",
   "metadata": {},
   "source": [
    "#### Define architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7c58f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_1 = 100\n",
    "n_latent_2 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c6294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c02297b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mnist_recurrent(n_steps=n_classes, input_size=784, mono=True):\n",
    "    model = nn.Sequential(\n",
    "        vnn.Recurrent(category_dim=n_steps, input_size=input_size, rnn_dim=n_latent_1,\n",
    "                      first_layer=False, first_rec_layer=True, last_layer=False, mono=mono),\n",
    "        vnn.Recurrent(category_dim=n_steps, input_size=n_latent_1, rnn_dim=n_latent_2,\n",
    "                      first_layer=False, first_rec_layer=False, last_layer=False, mono=mono),\n",
    "        vnn.Recurrent(category_dim=n_steps, input_size=n_latent_2, rnn_dim=1,\n",
    "                      first_layer=False, first_rec_layer=False, last_layer = True, mono=mono))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "799a54f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Recurrent()\n",
       "  (1): Recurrent()\n",
       "  (2): Recurrent()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recc_mnist = make_mnist_recurrent()\n",
    "recc_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914dbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recc_mnist._modules['1']._parameters['weight_hh'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d70448b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected shape torch.Size([96, 100])\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 0\n",
      "=============================\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 1\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 2\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 3\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 4\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 5\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 6\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 7\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 8\n",
      "Inter shape torch.Size([96, 100])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 100])\n",
      "Op shape torch.Size([10, 100])\n",
      "Timestep op calculated 9\n",
      "Out of for loop\n",
      "Layer 1 done\n",
      "========================================\n",
      "Input shape torch.Size([96, 10, 100])\n",
      "Projected shape torch.Size([96, 10, 50])\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([10, 50])\n",
      "Timestep op calculated 0\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 1\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 2\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 3\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 4\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 5\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 6\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 7\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 8\n",
      "==================================\n",
      "Inter shape torch.Size([96, 50])\n",
      "Inter done\n",
      "Mask shape torch.Size([1, 50])\n",
      "Op shape torch.Size([96, 50])\n",
      "Timestep op calculated 9\n",
      "==================================\n",
      "Out of for loop\n",
      "Layer done\n",
      "==========================================\n",
      "Input shape torch.Size([96, 10, 50])\n",
      "Projected shape torch.Size([96, 10, 1])\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 0\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 1\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 2\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 3\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 4\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 5\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 6\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 7\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 8\n",
      "==================================\n",
      "Inter shape torch.Size([96, 1])\n",
      "Inter done\n",
      "Sigmoid works\n",
      "Timestep op calculated 9\n",
      "==================================\n",
      "Out of for loop\n",
      "Layer done\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "image_batch = image_batch.view(image_batch.shape[0], -1)\n",
    "output = recc_mnist(image_batch.to(dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fcc3c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 10, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recc_mnist._modules['0']._parameters['weight_ih'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23390bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recc_mnist._modules['1']._parameters['weight_ih'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "recc_mnist._modules['0']._parameters['weight_ih']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "### weight ih in layer 1 too seems to be non-neg\n",
    "### weights ih, hh in layer 2 seem to be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663dea1",
   "metadata": {},
   "source": [
    "#### Train recurrent model using GEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, train_loader, flatten, vectorized, learning_rule, device):\n",
    "    avg_loss_sum = 0. #sum of batch-avg loss vals\n",
    "    num_correct = 0 #sum of correct counts\n",
    "    num_examples = 0 #total # examples\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        input = format_input(data, flatten, vectorized)\n",
    "        opt.zero_grad()\n",
    "        if vectorized:\n",
    "            #vectorized BP or DF\n",
    "            with torch.no_grad(): #makes no difference...but this proves to ourselves that there's no gradient here!\n",
    "                output = model(input.to(device))[..., 0]\n",
    "            vnn.set_model_grads(model, output, labels, learning_rule=learning_rule, reduction=\"mean\")\n",
    "            loss = loss_fn(output, labels.to(device))\n",
    "        else:\n",
    "            #unvectorized BP or DF\n",
    "            output = model(input.to(device), learning_rule=learning_rule)\n",
    "            loss = loss_fn(output, labels.to(device))\n",
    "            loss.backward()\n",
    "        opt.step()\n",
    "        if vectorized:\n",
    "            vnn.post_step_callback(model)\n",
    "        else:\n",
    "            dfa_util.post_step_callback(model)\n",
    "        avg_loss_sum += loss.item()\n",
    "        num_correct += (output.detach().argmax(dim=1).cpu() == labels).int().sum().item()\n",
    "        num_examples += len(data)\n",
    "    epoch_loss = avg_loss_sum / (batch_idx + 1)\n",
    "    epoch_accuracy = num_correct / num_examples\n",
    "    print(\"loss: {}, accuracy: {}\".format(epoch_loss, epoch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500b8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(snapshot_dir, model, train_loader, test_loader, eval_iter, lr, num_epochs,\n",
    "    flatten, vectorized, learning_rule, device):\n",
    "    model = model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    snapshot_epoch, just_restarted, done_training = restart_from_snapshot(snapshot_dir, model, opt)\n",
    "    if done_training or snapshot_epoch >= num_epochs:\n",
    "        print(\"Loaded model already done training\")\n",
    "        return\n",
    "    for epoch in range(snapshot_epoch, num_epochs):\n",
    "        if epoch % eval_iter == 0 and not just_restarted:\n",
    "            train_accuracy, train_loss = eval_accuracy(model, train_loader, flatten, vectorized, device)\n",
    "            test_accuracy, test_loss = eval_accuracy(model, test_loader, flatten, vectorized, device)\n",
    "            save_snapshot(snapshot_dir, model, opt, epoch, train_loss, train_accuracy, test_loss, test_accuracy,\n",
    "                flatten, vectorized, learning_rule)\n",
    "            if train_accuracy == 1.0:\n",
    "                print(\"Perfect train accuracy achieved, ending training at epoch {}\".format(epoch))\n",
    "                break\n",
    "        just_restarted = False\n",
    "        train_epoch(model, opt, train_loader, flatten, vectorized, learning_rule, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55780c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_dir = '../mnist_recc_trials_v1/'\n",
    "recc_mnist = recc_mnist()\n",
    "mnist_train_loader, mnist_test_loader = load_mnist()\n",
    "eval_iter = 1\n",
    "eta = 0.001\n",
    "n_epochs = 10\n",
    "flatten_bool = True\n",
    "vec_bool = True\n",
    "rule=\"df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7325b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(snap_dir, vnn_fc_mnist, mnist_train_loader, mnist_test_loader, eval_iter, eta, n_epochs, flatten_bool, vec_bool, rule, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763111bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173be4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.rand(1,6)\n",
    "out_features, in_features = weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864edab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight[:] = 0.\n",
    "W = torch.randn(max(out_features//2, 1), in_features//2, device=weight.device) / np.sqrt(0.25 * in_features)\n",
    "\n",
    "# weight[::2, ::2] = F.relu(W)\n",
    "# weight[::2, 1::2] = F.relu(-W)\n",
    "\n",
    "# if out_features > 1:\n",
    "#     weight[1::2, ::2] = F.relu(-W)\n",
    "#     weight[1::2, 1::2] = F.relu(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be08d2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6dfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722266c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

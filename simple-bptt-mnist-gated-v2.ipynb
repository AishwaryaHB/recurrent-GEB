{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede197e5",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89b4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c606816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b22af",
   "metadata": {},
   "source": [
    "#### Test for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba2ce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU, training on CPU\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('No GPU, training on CPU')\n",
    "    dev = torch.device('cpu')\n",
    "else:\n",
    "    print('GPU found, training on GPU')\n",
    "    dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2b541",
   "metadata": {},
   "source": [
    "#### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d548a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure batch_size = 1 for now!!\n",
    "\n",
    "def load_mnist(batch_size=1, shuffle_train=True):\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_set = torchvision.datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "    test_set = torchvision.datasets.MNIST(\"../data\", train=False, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=shuffle_train)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a3feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_loader, mnist_test_loader = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94238cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(mnist_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dade45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9de244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## change to appropriate shapes!!\n",
    "image_batch = torch.squeeze(image_batch).reshape(1,-1)\n",
    "image_batch = image_batch.repeat(n_classes,1)\n",
    "label_batch = F.one_hot(label_batch,n_classes).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f6be7",
   "metadata": {},
   "source": [
    "#### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b227d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule:\n",
    "    \"\"\"An RNN cell responsible for a single timestep.\n",
    "\n",
    "    Args:\n",
    "        inp_dim (int): Input size.\n",
    "        hid_dim (int): Hidden size.\n",
    "        out_dim (int): Output size.\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_dim, hid_dim, out_dim):\n",
    "        self.inp_dim = inp_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.out_dim = out_dim\n",
    "        n_classes = 10 ## NOTE: Edit as needed!!\n",
    "\n",
    "        ## Wih, Whh, Woh are the parameters, so we set requires_grad=True\n",
    "        self.Wih = torch.empty(hid_dim, inp_dim, requires_grad=True)\n",
    "        self.Whh = torch.empty(hid_dim, hid_dim, requires_grad=True)\n",
    "        self.Woh = torch.empty(out_dim, hid_dim, requires_grad=True)\n",
    "\n",
    "        ## These are the gradients on Wih, Whh, and Woh computed manually\n",
    "        ## Will be compared to the gradients computed by PyTorch\n",
    "        self.Wih_grad = torch.zeros_like(self.Wih)\n",
    "        self.Whh_grad = torch.zeros_like(self.Whh)\n",
    "        self.Woh_grad = torch.zeros_like(self.Woh)\n",
    "        \n",
    "        ## Gating vector\n",
    "        self.tvec = torch.zeros(n_classes,hid_dim)\n",
    "        for ii in range(n_classes):\n",
    "            t_half = torch.randint(0, 2, (1, hid_dim//2)).float()*2 - 1\n",
    "            self.tvec[ii,::2] = t_half\n",
    "            self.tvec[ii,1::2] = -t_half\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Initialize parameters.\n",
    "\n",
    "        The parameters will be initialized from the uniform\n",
    "        distribution U(-0.1, 0.1).\n",
    "        \"\"\"\n",
    "        s = 0.1  # larger value may make the gradients explode\n",
    "        torch.nn.init.uniform_(self.Wih, -s, s)\n",
    "        torch.nn.init.uniform_(self.Whh, 0, s)\n",
    "        torch.nn.init.uniform_(self.Woh, 0, s)\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        \"\"\"Set the gradients to zero.\"\"\"\n",
    "        self.Wih_grad.zero_()\n",
    "        self.Whh_grad.zero_()\n",
    "        self.Woh_grad.zero_()\n",
    "\n",
    "    def forward(self, x, hp, kk):\n",
    "        \"\"\"Perform the forward computation.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input at the current timestep.\n",
    "            hp (Tensor): Hidden state at the previous timestep.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Output at the current timestep.\n",
    "            Tensor: Hidden state at the current timestep.\n",
    "        \"\"\"\n",
    "        _, h, _, y = self._get_internals(x, hp, kk)\n",
    "        return y, h\n",
    "\n",
    "    def backward(self, y_grad, rn_grad, x, hp, kk):\n",
    "        \"\"\"Perform the backward computation.\n",
    "        \n",
    "        Args:\n",
    "            y_grad (Tensor): Gradient on output at the current timestep.\n",
    "            rn_grad (Tensor): Gradient on vector r at the next timestep.\n",
    "            x (Tensor): Input at the current timestep that was passed to `forward`.\n",
    "            hp (Tensor): Hidden state at the previous timestep that was passed to `forward`.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Gradient on vector r at the current timestep.\n",
    "        \"\"\"\n",
    "        # Get internal vectors r, h, and s from forward computation\n",
    "        r, h, s, _ = self._get_internals(x, hp, kk)\n",
    "\n",
    "        s_grad = y_grad * torch.sigmoid(s) * (1-torch.sigmoid(s)) ## note manual differentiation!!\n",
    "        h_grad = self.Woh.t().matmul(s_grad) + self.Whh.t().matmul(rn_grad)\n",
    "        r_grad = h_grad * ((self.tvec[kk]*r)>0)*1 ## note manual differentiation!!\n",
    "\n",
    "        # Parameter gradients are accumulated\n",
    "        self.Wih_grad += r_grad.view(-1, 1).matmul(x.view(1, -1))\n",
    "        self.Whh_grad += r_grad.view(-1, 1).matmul(hp.view(1, -1)) \n",
    "        self.Woh_grad += s_grad.view(-1, 1).matmul(h.view(1, -1)) \n",
    "\n",
    "        return r_grad\n",
    "    \n",
    "    def _get_internals(self, x, hp, kk):\n",
    "        # Actual forward computations\n",
    "        r = self.Wih.matmul(x) + self.Whh.matmul(hp)\n",
    "        h = ((self.tvec[kk]*r)>0)*r\n",
    "        s = self.Woh.matmul(h)\n",
    "        y = torch.sigmoid(s)\n",
    "        \n",
    "        return r, h, s, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d878f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, cell):\n",
    "        self.cell = cell\n",
    "    \n",
    "    def forward(self, xs, h0):\n",
    "        \"\"\"Perform the forward computation for all timesteps.\n",
    "        \n",
    "        Args:\n",
    "            xs (Tensor): 2-D tensor of inputs for each timestep. The\n",
    "                first dimension corresponds to the number of timesteps.\n",
    "            h0 (Tensor): Initial hidden state.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: 2-D tensor of outputs for each timestep. The first\n",
    "                dimension corresponds to the number of timesteps.\n",
    "            Tensor: 2-D tensor of hidden states for each timestep plus\n",
    "                `h0`. The first dimension corresponds to the number of\n",
    "                timesteps.\n",
    "        \"\"\"\n",
    "        ys, hs = [], [h0]\n",
    "        for ii, x in enumerate(xs):\n",
    "            y, h = self.cell.forward(x, hs[-1],ii)\n",
    "            ys.append(y)\n",
    "            hs.append(h)\n",
    "        return torch.stack(ys), torch.stack(hs)\n",
    "    \n",
    "    def backward(self, ys_grad, xs, hs):\n",
    "        \"\"\"Perform the backward computation for all timesteps.\n",
    "        \n",
    "        Args:\n",
    "            ys_grad (Tensor): 2-D tensor of the gradients on outputs\n",
    "                for each timestep. The first dimension corresponds to\n",
    "                the number of timesteps.\n",
    "            xs (Tensor): 2-D tensor of inputs for each timestep that\n",
    "                was passed to `forward`.\n",
    "            hs (Tensor): 2-D tensor of hidden states that is returned\n",
    "                by `forward`.\n",
    "        \"\"\"\n",
    "        # For the last timestep, the gradient on r is zero\n",
    "        rn_grad = torch.zeros(self.cell.hid_dim)\n",
    "\n",
    "        for ii, (y_grad, x, hp) in enumerate(reversed(list(zip(ys_grad, xs, hs)))):\n",
    "            rn_grad = cell.backward(y_grad, rn_grad, x, hp, n_classes-ii-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ef10e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "hidden_dim = 100\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6aca40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = RNNModule(input_dim, hidden_dim, output_dim)\n",
    "rnn = RNN(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590043bd",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2727e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_cross_entropy(predictions, targets, epsilon=1e-15):\n",
    "#     \"\"\"\n",
    "#     Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "#     and predictions. \n",
    "#     Input: predictions (N, k) ndarray\n",
    "#            targets (N, k) ndarray        \n",
    "#     Returns: scalar\n",
    "#     \"\"\"\n",
    "#     predictions = torch.clip(predictions, epsilon, 1. - epsilon)\n",
    "#     N = predictions.shape[0]\n",
    "#     ce = -torch.sum(targets*torch.log(predictions+1e-12))/N\n",
    "    \n",
    "#     return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e780b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(ys, ts):\n",
    "    return 0.5 * torch.sum((ys - ts)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33eb821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note -- changed!!\n",
    "xs = image_batch\n",
    "hp = torch.zeros(cell.hid_dim)\n",
    "ts = label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f31f8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, hs = rnn.forward(xs, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc46c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, hs = rnn.forward(xs, hp)\n",
    "loss = compute_loss(ys, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fe4487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e7380",
   "metadata": {},
   "source": [
    "#### PyTorch gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "053ad27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gradient of cross entropy w.r.t. yhat_k = (1/yhat_k)*y_k\n",
    "## gradient of mse w.r.t. y_hat =   y_hat - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac4d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ab2b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Wih.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4054d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Whh.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a8bce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Woh.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f07a3",
   "metadata": {},
   "source": [
    "#### Manual gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64a3eb4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for dimension 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36332\\3439248314.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# required so PyTorch won't raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36332\\2472869811.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, ys_grad, xs, hs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mrn_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrn_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36332\\730835926.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, y_grad, rn_grad, x, hp, kk)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \"\"\"\n\u001b[0;32m     78\u001b[0m         \u001b[1;31m# Get internal vectors r, h, and s from forward computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_internals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0ms_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_grad\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## note manual differentiation!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36332\\730835926.py\u001b[0m in \u001b[0;36m_get_internals\u001b[1;34m(self, x, hp, kk)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# Actual forward computations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWih\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWhh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtvec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWoh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 11 is out of bounds for dimension 0 with size 10"
     ]
    }
   ],
   "source": [
    "# This is obtained from our loss function\n",
    "# ys_grad = torch.matmul(label_batch,ys)\n",
    "ys_grad = ys - ts\n",
    "\n",
    "with torch.no_grad():  # required so PyTorch won't raise error\n",
    "    rnn.cell.zero_grad()\n",
    "    rnn.backward(ys_grad, xs, hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601539f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Wih_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86292cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Whh_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.cell.Wih_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdad959",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.Woh_grad - rnn.cell.Woh.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25345d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.Whh_grad - rnn.cell.Whh.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38c20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.Wih_grad - rnn.cell.Wih.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c49b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1358ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a9045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
